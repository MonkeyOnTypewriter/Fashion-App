{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions for Building Data Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to need a lot of data. Its too annoying to collect it by hand, so we're automating the process. I have written some scripts for scraping images from Google and processing them into a usable format. I would like you to tidy them up and turn them into a single class. The idea is that we can just instantiate the class, make a request, and automatically get thousands of cleaned images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process is as follows:\n",
    "\n",
    "1. Search and download images from Google\n",
    "2. Remove duplicate images\n",
    "3. Convert images to jpg\n",
    "5. Resize images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the class, it would be nice if you could give it two methods: class.download_images() and class.process_images()."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class.download_images() should take a list of search terms as a parameter. It should store the downloaded images in an attribute. Depending on how you choose to do it, you might want to remove duplicates here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class.process_images() should operate on the downloaded images. It should take the parameter jpg size and return a list of processed jpgs. I think this should be a seperate method than download_images() because downloading images takes a long time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first script is 'google_images_scraper.py'. This script uses Selenium to download images from Google. Each time it runs, it takes a couple minutes. Also, for any particular search term, it will only download around 300 images. This means it has to be run multiple times with varied search terms in order to build a large dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Important Points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comments in the code are mostly nonsense. You should just ignore them. This is what the top of the script looks like:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alternative text](jnb/1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "query is the search term. num_images is the number of images that the sccript will attempt to download. There will be exceptions, so only about 300 images get downloaded."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using the firefox driver because thats what works on my computer. You might want to change it, but that might break the code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're going to run this code with multiple different search terms to get a large amount of images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Duplicates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two reasons we need to remove duplicates:\n",
    "\n",
    "- If we have the same image in the test and train set, we will do better on the testing than the model will actually perform in the wild.\n",
    "- If we have duplicates in the training data, we could overfit to that data point."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't have a script for removing duplicates. The way it works currently is 'google_images_scraper.py' saves each search in a folder named according to the search terms. Each file is named after the alphanumerics in the last 16 characters of the url it came from. Thus, if the same image was downloaded for two different searches, the files will have the same names. When we put all the files together in the same folder MacOS asks you if you want to remove duplicates. This isn't an ideal solution. You probably don't even need to save the images as files."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to jpg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scraper saves the images as docs. We need them to be jps in order to process them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script that does this is 'doc_to_jpg.py'. It opens a folder that contains docs and save all the files as jpgs in another folder. Again, it is not necessary to save the files here since they will just be passed to the next script anyway. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize Images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the script 'resize_jpg.py' does. Right now it is set to make 640x640 images. It would be nice to make the final size a parameter. Also, this script should be combined with 'doc_to_jpg.py' into a single method. The method should return a list of finished images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
